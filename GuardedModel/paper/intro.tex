% !TeX root = main.tex
% !TeX spellcheck = en-CA
%%% TeX-command-extra-options: "-shell-escape"

\section{Introduction}

Gradual dependent give principled static and dynamic semantics to programs where part of a type or term is missing.
By allowing imprecision, gradual dependent types allow for smooth migration of code
from non-dependently typed languages, or even untyped languages, to full dependent types,
allowing the programmer run and test their code even when the full type details haven't been figured out.
% Likewise, the common practice of ``programming by holes''~\citep{idrisBook} is enhanced:
% code containing holes can still be safely run or tested.
This migration is easiest in languages fulfilling the \textit{gradual guarantees} of
\citet{refinedCriteria}, which state replacing part of a program with $\gqm$ creates no new
static or dynamic type errors. The gradual guarantees ensure that, when an error is encountered,
the problem is never too few types, but that two types in the program are fundamentally incompatible.

However, the benefits of gradual dependent types have not been realized,
since existing developments have enabled the gradual guarantees
at the expense of other desirable properties.
\Citet{Eremondi:2019:ANG:3352468.3341692} presented GDTL, a dependent calculus supporting the gradual guarantees,
but relied on a termination argument that does not scale to inductive types.
\Citet{bertrand:gcic} presented GCIC, with two extensions of the Calculus of Inductive Constructions (CIC)
that satisfy the gradual guarantees, but one
has undecidable type checking and the other rejects some well-typed static CIC programs.
% The third GCIC variant has decidable type checking and conservatively extends CIC, but does not support
% the gradual guarantees.

\Citet{bertrand:gcic} show that, to a degree, these sacrifices are unavoidable, to a degree:
no dependently typed language can satisfy all of
strong normalization, conservative extension of CIC, and \textit{graduality},
a strengthening of the gradual guarantees.


Another obstacle to the adoption of gradual dependent types
is that gradual dependent types have not yet been meaningfully implemented.
Constructing a compiler for a dependently typed language is a massive engineering effort,
and involves writing a type checker, a convertability check for terms, and unification engine for inference,
in addition to the code generation and optimization.
Writing a compiler for a gradual dependently typed language involves all of this work, plus extra
handling to ensure safety in the presence of type imprecision.


% On the theoretical side, the story of gradual dependent types thus far has been one of compromise.
% Several systems have been developed that support limited forms of dependency, such as
% refinement types~\citep{Lehmann:2017:GRT:3009837.3009856,zalewskilambdadb}
% or label-dependent types~\citep{10.1145/3485485}
% \Citet{Eremondi:2019:ANG:3352468.3341692} presented GDTL,
% a foundational calculus with full dependent types.
% GDTL features
% decidable type checking,
% and allowed the imprecise term $\gqm$ to replace any part of a term or type.
% However, the termination argument for GDTL does not support inductive types.
% The most comprehensive development of gradual dependent types is GCIC~\citep{bertrand:gcic},
% which extends the Calculus of Inductive Constructions (CIC) with gradual types.
% GCIC comes in three, each of which satisfies two of the following properties:
% (1) decidable type checking, (2) the gradual guarantees, and (3) conservatively extending CIC.
% \je{TODO: mention equality if either paper gets accepted}
% The authors show that, to a degree, the compromise of GCIC is necessary:
% they establish a ``fire-triangle'' theorem that shows no dependently typed language can satisfy
% strong normalization, conservative extension of CIC, and the Embedding-Projection Pairs (EP-pairs) property,
% a strengthening of the gradual guarantees.


% In this paper, we take the view that the fire triangle properties are means to an end,
% rather than ends unto themselves. Conservatively extending CIC is a useful trait on its own,
% since it ensures that no ill-typed static programs are allowed in a gradual language.
% Strong normalization, conversely, is mainly useful to
% prove that type-checking is decidable, as well as to establish logical consistency.
% Likewise, EP-pairs are mainly useful for showing the gradual guarantees, and showing that
% gradual programs to not unnecessarily produce $\gqm$ as their result.

We address both these shortcomings in \lang, a \underline{Gr}adual language with \underline{Ind}uctive types.
\lang sacrifices
strong normalization and graduality, but keeps the properties that we actually want: decidable type checking,
(weak) canonicity, the gradual guarantees, and conservatively extending CIC.
Because type checking is decidable, \lang can be translated into the core calculi of existing dependently typed compilers.
Moreover, we show that \lang does not violate static reasoning principles: propositionally-equal
CIC terms embedded in \lang are observationally-equivalent,
and casts only change the error-behavior of terms, not the concrete results produced, a
notion which we call \textit{weak graduality}.
% and while we lack full EP-pairs,
% we show that casts only change the behaviour of terms relative to dynamic type errors:
% applying casts may produce a term that raises an error in more or less situations, but when a concrete
% result is produced, it is the same result.
% \je{TODO explain EP pairs}

Our main contribution is a translation from \lang to a static type theory:
\begin{itemize}
          \item For implementation, the translation means that existing normalizers
                and code generators can be used ``off-the-shelf'' to compile \lang programs;
  \item For metatheory, the translation serves as a syntactic model in the style of \citet{10.1145/3018610.3018620}, which we use to prove the gradual guarantees
        and other metatheoretic properties;
  \item To enable decidable type checking, we adapt approximate normalization
        from \citet{Eremondi:2019:ANG:3352468.3341692} to a cast calculus, using the syntactic
        model to prove termination;
  \item To model run-time semantics, we translate to \textit{guarded type theory}~\citep{TODO},
        whose non-positive recursive types allow the non-termination of gradual types to be
        exactly represented in a consistent target language;
  \item  Our translation and the theorems about it have been mechanized in Guarded Cubical Agda~\citep{TODO}
\end{itemize}

\section{Two Problems, One Solution}

Our work attacks two main problems that have a common solution.
First, we want to allow \lang to be implemented
by translating them to static dependent types without needing to add features to the static target langauge,
so that existing technology can be
used when compiling them.
The challenge here is accommodating the non-termination of gradual typing,
since dependently typed core languages typically forbid or restrict non-terminating function definitions.
Second, we want to prove properties about \lang, namely that approximate normalization
terminates (for decidable type checking) and that the gradual guarantees are satisfied.
Unlike the approach of \citet{Eremondi:2019:ANG:3352468.3341692}, the syntactic model
approach scales to handle inductive types, as well as logical-relation
style proofs~\citep{10.1017/S0956796812000056}.

In this section, we explain these two problems, the challenges in solving
them, and a birds-eye view of our approach to solving them.

Throughout, we refer to terms from several languages. For clarity,
we write terms from CIC, the static starting language, in \staticdesc,
terms from \lang,  the gradual cast calculus, in \gradualdesc,
and terms from the guarded type theory, the target of translation,
in \targetdesc.



\subsection{Translation to Support Implementation}

\subsubsection{Don't Reinvent the Wheel}
Even without gradual types, implementing a dependently typed language is a formidable task.
Because types may depend on terms, checking that two types are equal involves
determining if those two types \textit{convertible}, i.e., if they are equal
after some number of reductions. Such a check must be implemented carefully,
usually using Normalization by Evaluation (NbE)~\citep{TODO}, to ensure that
only well-typed terms are normalized so the check terminates.
Support for type inference and implicit arguments to functions
involves a writing higher-order unification algorithm. Most dependently typed languages
have some form of proof-search, tactics, or reflection, to automate the generation of
trivial but tedious proofs.

Even with the above features implemented, implementing them
efficiently is even more difficult.
Conversion checking is a costly operation,
and while it can be implemented by fully normalizing the compared terms,
this likely performs more computation than is necessary to see whether the terms
are definitely convertible or not. Recent experiments in Idris have shown that
on-the-fly compilation of terms can provide efficient normalization~\citep{TODO}.
For code generation, since the return type of a function can depend on the value of its argument,
the generation of machine code more closely resembles a dynamic language, but from an optimization
standpoint, programs contain a wealth of type information that can be used to optimize said dynamic code.
Moreover, dependently typed programs may contain indices or function arguments
that are needed only because of type dependency, but are unused during run time~\citep{TODO}.
Additional optimizations are needed to identify and remove unused terms from the generated code.
Gradual dependent types should support the latest and greatest
techniques for efficiency in both the compiler and compiled code.


\subsubsection{An Implementation Strategy}

To avoid re-implementing the above tools for gradual dependent types, our implementation
strategy is to first translate gradual dependent programs to a static dependently typed language.
Then, existing implementations of conversion checking, unification, optimization and code-generation
can be freely used on the result of translation.
A gradual dependently typed language can simply be a new front-end to an existing dependently typed language,
such as Agda or Idris.

The challenge with this approach is that, to reuse existing infrastructure,
we must be able to translate gradual dependent types to static dependent types
\textit{without changing the static core language}.
Gradual dependently typed programs do not always terminate,
and may raise run-time type errors.
However, the termination
of static tools relies on the termination of static programs.
Escape hatches exist, like Agda's \texttt{\{-\# TERMINATING \#-\}} pragma,
but using such features is morally wrong, as these features are intended for cases
where programs do terminate, but their termination is difficult or impossible to
prove within the type theory itself.
Instead, we must work within more conservative features for taming non-terminaton.

\subsubsection{Idris and Agda's Models of Non-Termination}

In Idris, all definitions are marked as either \texttt{partial} or \texttt{total}.
Those that are marked \texttt{total} can only refer to others
that are marked \texttt{total}. Recursive \texttt{total} functions are checked
to ensure that recursive calls are only made to smaller arguments, and \texttt{total}
inductive datatypes must be strictly positive (i.e. self-reference may only occur)
to the right of function arrows in fields).
By contrast, \texttt{partial} functions allow for general recursion and non-positive datatypes,
and

The key to keeping type-checking decidable is to never normalize \texttt{partial} terms.
In Idris, when a type depends on a \texttt{partial} function, the definition of that function
is kept abstract.%
\footnote{
  In Idris 1, this behaviour was implemented in the compiler. Idris 2 has yet to implement
  this behavior, and happily runs the type checker forever when comparing non-terminating terms.
  However, safety can be recovered by defining partial functions in their own module,
  and exposing them with \texttt{export} rather than \texttt{public export}, which reveals
  their types while keeping their definitions abstract.
}%
%
This convention allows for trivial equalities to be satisfied, like a term being equal to itself.
Two terminating terms that are marked \texttt{partial} are not considered definitionally equal
even if they have the same evaluation, because normalization is required to see
that they are equal.
Agda has a similar model: definitions may be marked as \texttt{\{-\# NON\_TERMINATING \#-\}},
which allows for general recursion but prevents such definitions from reducing during type checking.

The issue with these models is that they are difficult to reason about in the abstract.
Running the type-checker immediately reveals whether a particular definition type checks with \texttt{partial} annotations. However, we wish to prove that our gradual to static translation
produces well typed code for \textit{all} outputs, but doing so requires reasoning about
the internal details of Idris or Agda's normalization algorithm.

To simplify the proof of our translation's type preservation, we instead turn to
\textit{guarded type theory}. We explain more details of guarded type theory in \cref{subsec:guardedIntro},
but for now it suffices to say that guarded type theory allows for a restricted form of general
recursion and non-positive datatypes, by placing such self-reference behind a separate modality,
and establishing fixed-point equalities as propositional equalities, rather than definitional equalities.
Guarded type theory provides a convenient formalism for reasoning about when definitions are normalized,
and allows us to mechanize our translation in Guarded Cubical Agda~\citet{TODO}.
Then, the primitives of guarded type theory can be easily implemented using the less restrictive
\texttt{partial} annotations of Agda and Idris,
allowing us to prove that the resulting code is always well typed.

\subsubsection{Translating Approximate Normalization}

While guarded type theory allows us to represent non-terminating terms at the type level,
it provides no clues as to actually devise a gradual type system for which checking is
decidable. However, previous work on gradual dependent types does provide clues.
\Citet{bertrand:gcic} were able to provide a syntactic model of GCIC
without decidable type-checking
by extending CIC with a non-positive datatypes, then translating the unknown type $\gqm$
to a non-positive inductive type $\r{Unk} := \r{(Unk -> Unk) + (Unk \times Unk) + (List\ Unk)\ldots}$.
\Citet{Eremondi:2019:ANG:3352468.3341692} were able to obtain terminating type level computations
in GDTL with \textit{approximate normalization}: terms occurring within types were given a separate semantics
that produced $\gqm$ whenever there was not enough type information to ensure termination.


We combine these two strategies to obtain a translation with decidable type checking.
Like GDTL, \lang has separate semantics for compile-time normalization and run-time execution.
However, GDTL had totally separate approximate and exact semantics, where
approximation was based on hereditary substitution, no formal notion related the two semantics.
Our approximate and exact semantics are identical except for one part: casts between $\gqm$
and $\g{\gqm \to \gqm}$. Instead of relying on hereditary substitution, we use the GCIC approach
and translate it to CIC: the approximations mean that only
strictly-positive datatypes are used, and hence termination is guaranteed.


\subsection{Metatheory}

\subsubsection{Extinguishing the Fire Triangle}

\begin{table}
  \label{tab:language-comp}
  \scriptsize
  \begin{tabular}{ |m{4em}|m{4em}|m{5em}|m{5em}|m{5em}|m{5em}|m{4em}||m{4em}|m{4em}|m{4em}| }
    \hline
  \textbf{Language} & Decidable type checking & Gradual Guarantees & Conservative Over CIC & Weak\ \ \ \  Graduality & Weak Canonicity & Inductives & Graduality & Strong Normalization\\
  \hline
    GDTL & \cmark & \xmark* & \xmark & ? & \cmark & \xmark & \xmark & \xmark \\
  \hline
    $GCIC^{\mathcal{G}}$ & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \xmark \\
  \hline
    $GCIC^{\mathcal{N}}$ & \cmark & \xmark & \cmark & \xmark & \cmark & \cmark & \xmark & \cmark \\
  \hline
    $GCIC^{\uparrow}$ & \cmark & \cmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
  \hline
    \lang & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \xmark & \xmark \\
  \hline
  \end{tabular}
  \caption{Gradual Dependent Languages: Feature Comparison}
\end{table}

When developing GCIC, \citet{bertrand:gcic} establish a ``fire-triangle'' theorem
stating that no language
could conservatively extend CIC while having strong normalization and graduality.
Here, graduality is the property defined by \citet{10.1145/3236768}, where
casting to a more precise type and back produces a term that is as precise as the original,
and casting to a less precise type and back produces an observationally-equivalent term.
The name is chosen by analogy with parametricity: just as parametricity is a
logical relation strengthening type safety, graduality is a logical relation
strengthening the gradual guarantees.
GCIC is then presented with three variants: one without decidable type checking,
one without the gradual guarantees, and one that rejects some well-typed CIC programs.

In this paper, we take the view that for programming languages specifically,
strong normalization and graduality are means to an end, rather than ends unto themselves.
Specifically, we want strong normalization to prove decidable type checking and weak canonicity
i.e. that all normal-forms of a term are either canonical, $\gqm$, or an error $\err$.
Strong normalization is also required for weak logical consistency: \lang does not have this,
but we discuss how to recover a form of it in \cref{subsec:static-reason}.
We want graduality to prove the gradual guarantees, as well as to establish that $\gqm$
is never needlessly produced as a result. (Such a property is desirable because a language that produces $\gqm$ as a result
of all casts is useless, but still technically satisfies the gradual guarantees.)

So while \lang cannot simultaneously have all three fire-triangle properties,
it can have all the properties we actually want:
decidable type checking, the gradual guarantees, and conservatively extending CIC.
\Cref{tab:language-comp} compares the features of GDTL, the three variants of GCIC, and \lang:
while \lang sacrifices strong normalization and graduality, we are able to recover
all the other desired properties despite this.

However, proving these properties is not trivial.
GDTL proved decidability of type checking using hereditary substitution, which does not
scale well to inductive types.
The gradual guarantees were proved using a simulation argument, but the proof
was complex and delicate.
While a syntactic model was used, the $GCIC^{\mathcal{G}}$ variant that embeds CIC and has the gradual guarantees
required non-positive datatypes, so the model was by a translation to an inconsistent logic,
and the target type theory could not be used to prove theorems about $GCIC^{\mathcal{G}}$.
For the other variants, strong normalization was shown in a syntactic model by sacrificing either embedding CIC
or the gradual guarantees.

Our implementation strategy works equally well for proving that type checking is decidable:
if we can translate approximate normalization into the total fragment of a type theory,
then it must be terminating. Then, by translating our exact semantics into
guarded type theory, we are able to prove the gradual guarantee in the type theory itself.
Unlike CIC with non-positive types, guarded type theory is logically consistent, so
the theorems proved about the translations of gradual programs can be believed.


\subsubsection{Static Reasoning in Gradual Code}
\label{subsec:static-reason}

In addition to the gradual guarantees, there are two properties about \lang that our translation
allows us to prove:
\begin{itemize}
  \item Preservation of Propositional Equality: this is the property that, for any two static CIC terms
        $\s{s}, \s{t} : \s{T}$, if we have a proof that $\s{s ==_{T} t}$, then
        when we embed $\s{s}$ and $\s{t}$ into \lang, the resulting $\g{s}$ and $\g{t}$
        are observationally equivalent. This guarantees that static reasoning principles
        still hold for fully static code that is used in gradual programs.
        For example, any optimizations
        that are valid for static code are still valid if that code is imported by a gradual library.

        The preservation of equality is a weaker version of the gradual full-abstraction property described by
        \citet{10.1145/3434288}, which says that all observationally-equivalent static programs
        are observationally-equivalent when embedded in the gradual language.
        Full abstraction is difficult to prove for \lang, since the conventional strategy
        requires the ability to translate any \lang context into an equivalent CIC one, which is
        impossible since CIC lacks non-termination as an effect.
        Proving that propositionally-equal static terms are gradually-equivalent provides a good first
        step, however, to ensuring that static is preserved gradually.
        \je{TODO: check if this prevents the bad example from DeVrise paper}
        \je{TODO: can we prove FA with funExt, by turning (x : T) into $\lambda (C : T -> B)\ldotp C x$ and using fun-ext? }
        \je{TODO: can we prove FA from CIC->GuardedTT FA?}

  \item Weak graduality: while we do not prove the strong graduality property of \citet{10.1145/3236768},
        we can prove a weaker version that establishes the same desirable property.

        In principle, it should be possible to prove strong graduality for a variant of \lang
        that ensured that approximate normal forms were never used at run-time, since the approximation
        when converting functions to and from $\gqm$ is what breaks the property.
        However, such a language would introduce the possibility that computations internal
        to run-time type information could non-terminate. These would be exceedingly difficult
        for the programmer to debug, since such computations are automatically inserted by the compiler
        and are meant to be opaque to the programmer. So


\end{itemize}

Approximate normalization also let us recover a form of weak logical consistency:
any closed term of type $\g{False}$ must have an approximate normal form that is either
the unknown term $\gqm$ or a run-time type error $\err$.
This is useful for proofs that are not used in computation, but serve as
validation that some desired property holds.
Because some \lang programs are non-terminating, it is possible to write
closed terms of statically-empty types that do not evaluate to $\gqm$ or $\err$.
However, inspecting the approximate-normal forms of such proofs can inform the programmer
about places where type-imprecision caused approximation, directing them
to where type imprecision forced approximation.
If a term of a fully-static type has a fully-static approximate normal form, then
the programmer can be confident in the truth of its Curry-Howard interpretation,
even if the proof itself uses imprecise types or terms.




\subsection{Modelling Gradual Dependent Types}


\subsubsection{Modelling Approximate Normalization}

\subsubsection{Guarded Type Theory}
\label{subsec:guardedIntro}

\subsubsection{Relating Approximate and Exact Normalization}
